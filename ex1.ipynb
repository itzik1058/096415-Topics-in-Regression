{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Normal RMSE: 0.004016624176857915\nExp RMSE: 0.02849942661032183\n"
     ]
    }
   ],
   "source": [
    "x_normal = np.random.standard_normal(size=100000)\n",
    "x_exp = np.random.standard_exponential(size=100000) - 1\n",
    "errors = {'Normal': [], 'Exp': []}\n",
    "for a, b, c in product([-1, 0, 1], repeat=3):\n",
    "    for dist, x in [['Normal', x_normal], ['Exp', x_exp]]:\n",
    "        y = a + b * x + c * x ** 2\n",
    "        ols = sm.OLS(y, np.c_[np.ones(x.shape[0]), x])\n",
    "        ols_results = ols.fit()\n",
    "        params = ols_results.params\n",
    "        expected = np.array([a + c, b]) if dist == 'Normal' else np.array([a + c, 2 * c + b])\n",
    "        errors[dist].append(np.square(params - expected))\n",
    "print('Normal RMSE:', np.sqrt(np.mean(errors['Normal'])))\n",
    "print('Exp RMSE:', np.sqrt(np.mean(errors['Exp'])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "source": [
    "We can see that the RMSE for both normal and exponential models are close to zero, therefore we conclude that our theoretical calculations are validated using simulation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question 6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameters for Model 1:\ntotal_bill    0.092713\nsize          0.192598\nbias          0.668945\ndtype: float64\nParameters for Model 2:\ntotal_bill     0.081881\nsize           0.093269\ninteraction    0.003941\nbias           0.918271\ndtype: float64\n"
     ]
    }
   ],
   "source": [
    "tips = pd.get_dummies(sn.load_dataset('tips'))\n",
    "y = tips[['tip']]\n",
    "x1 = tips[['total_bill', 'size']]\n",
    "x2 = x1.assign(interaction=x1['total_bill'] * x1['size'])\n",
    "for name, x in [['Model 1', x1], ['Model 2', x2]]:\n",
    "    ols = sm.OLS(y, x.assign(bias=1))\n",
    "    results = ols.fit()\n",
    "    params = results.params\n",
    "    print(f'Parameters for {name}:')\n",
    "    print(params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "source": [
    "Including the interaction term significantly decreased the effect of the size parameter on the tip while only decreasing the effect of the total_bill parameter mildly. We suspect that some of the effect of the size parameter is now accounted for in the interaction term. The values of total_bill are on a higher scale than the values of size, causing the paramater to have lower weight. Naturally, the bias term changed slightly."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ae8abb109cfabdbbe97353ff4e2f19de49e078fc8e78e0a0da7073003fc7d8b7"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}